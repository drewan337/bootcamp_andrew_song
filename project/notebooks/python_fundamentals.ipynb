{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15bd18d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STAGE 03: PYTHON FUNDAMENTALS ===\n",
      "Utility functions defined and ready for use\n",
      "\n",
      "=== STAGE 04: DATA ACQUISITION ===\n",
      "✓ Data acquired: 126 rows, 8 columns\n",
      "   Missing values: 0\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>dividends</th>\n",
       "      <th>stock splits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-02-24 00:00:00-05:00</td>\n",
       "      <td>338.140015</td>\n",
       "      <td>342.399994</td>\n",
       "      <td>324.700012</td>\n",
       "      <td>330.529999</td>\n",
       "      <td>76052300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-02-25 00:00:00-05:00</td>\n",
       "      <td>327.019989</td>\n",
       "      <td>328.890015</td>\n",
       "      <td>297.250000</td>\n",
       "      <td>302.799988</td>\n",
       "      <td>134228800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-02-26 00:00:00-05:00</td>\n",
       "      <td>303.709991</td>\n",
       "      <td>309.000000</td>\n",
       "      <td>288.040009</td>\n",
       "      <td>290.799988</td>\n",
       "      <td>100118300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-02-27 00:00:00-05:00</td>\n",
       "      <td>291.160004</td>\n",
       "      <td>297.230011</td>\n",
       "      <td>280.880005</td>\n",
       "      <td>281.950012</td>\n",
       "      <td>101748200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-02-28 00:00:00-05:00</td>\n",
       "      <td>279.500000</td>\n",
       "      <td>293.880005</td>\n",
       "      <td>273.600006</td>\n",
       "      <td>292.980011</td>\n",
       "      <td>115697000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       date        open        high         low       close  \\\n",
       "0 2025-02-24 00:00:00-05:00  338.140015  342.399994  324.700012  330.529999   \n",
       "1 2025-02-25 00:00:00-05:00  327.019989  328.890015  297.250000  302.799988   \n",
       "2 2025-02-26 00:00:00-05:00  303.709991  309.000000  288.040009  290.799988   \n",
       "3 2025-02-27 00:00:00-05:00  291.160004  297.230011  280.880005  281.950012   \n",
       "4 2025-02-28 00:00:00-05:00  279.500000  293.880005  273.600006  292.980011   \n",
       "\n",
       "      volume  dividends  stock splits  \n",
       "0   76052300        0.0           0.0  \n",
       "1  134228800        0.0           0.0  \n",
       "2  100118300        0.0           0.0  \n",
       "3  101748200        0.0           0.0  \n",
       "4  115697000        0.0           0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== STAGE 05: DATA STORAGE ===\n",
      "✓ Raw data saved: C:/Users/박서아/bootcamp_andrew_song/project/data/raw/tsla_raw_20250823-222146.csv\n",
      "✓ Raw data saved: C:/Users/박서아/bootcamp_andrew_song/project/data/processed/tsla_20250823-222146.parquet\n",
      "\n",
      "=== STAGE 06: DATA PREPROCESSING ===\n",
      "✓ Processed data saved: C:/Users/박서아/bootcamp_andrew_song/project/data/processed/tsla_processed.csv\n",
      "\n",
      "Preprocessing results:\n",
      "Rows: 126 → 126\n",
      "Columns: 8 → 19\n",
      "Missing values: 0 → 142\n",
      "\n",
      "Processed data sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>dividends</th>\n",
       "      <th>stock splits</th>\n",
       "      <th>sma_10</th>\n",
       "      <th>sma_20</th>\n",
       "      <th>sma_50</th>\n",
       "      <th>daily_return</th>\n",
       "      <th>weekly_return</th>\n",
       "      <th>volatility_10</th>\n",
       "      <th>volatility_20</th>\n",
       "      <th>price_sma_10_ratio</th>\n",
       "      <th>price_sma_20_ratio</th>\n",
       "      <th>next_day_close</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-02-24 00:00:00-05:00</td>\n",
       "      <td>1.057447</td>\n",
       "      <td>1.002706</td>\n",
       "      <td>0.884151</td>\n",
       "      <td>0.861557</td>\n",
       "      <td>-0.986105</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>302.799988</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-02-25 00:00:00-05:00</td>\n",
       "      <td>0.756665</td>\n",
       "      <td>0.625205</td>\n",
       "      <td>0.155447</td>\n",
       "      <td>0.097643</td>\n",
       "      <td>0.575563</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.804920</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>290.799988</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-02-26 00:00:00-05:00</td>\n",
       "      <td>0.126159</td>\n",
       "      <td>0.069430</td>\n",
       "      <td>-0.089047</td>\n",
       "      <td>-0.232936</td>\n",
       "      <td>-0.340086</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.867485</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>281.950012</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-02-27 00:00:00-05:00</td>\n",
       "      <td>-0.213303</td>\n",
       "      <td>-0.259451</td>\n",
       "      <td>-0.279120</td>\n",
       "      <td>-0.476738</td>\n",
       "      <td>-0.296334</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.672717</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>292.980011</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-02-28 00:00:00-05:00</td>\n",
       "      <td>-0.528691</td>\n",
       "      <td>-0.353059</td>\n",
       "      <td>-0.472379</td>\n",
       "      <td>-0.172881</td>\n",
       "      <td>0.078102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800258</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>284.649994</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       date      open      high       low     close    volume  \\\n",
       "0 2025-02-24 00:00:00-05:00  1.057447  1.002706  0.884151  0.861557 -0.986105   \n",
       "1 2025-02-25 00:00:00-05:00  0.756665  0.625205  0.155447  0.097643  0.575563   \n",
       "2 2025-02-26 00:00:00-05:00  0.126159  0.069430 -0.089047 -0.232936 -0.340086   \n",
       "3 2025-02-27 00:00:00-05:00 -0.213303 -0.259451 -0.279120 -0.476738 -0.296334   \n",
       "4 2025-02-28 00:00:00-05:00 -0.528691 -0.353059 -0.472379 -0.172881  0.078102   \n",
       "\n",
       "   dividends  stock splits  sma_10  sma_20  sma_50  daily_return  \\\n",
       "0        0.0           0.0     NaN     NaN     NaN           NaN   \n",
       "1        0.0           0.0     NaN     NaN     NaN     -1.804920   \n",
       "2        0.0           0.0     NaN     NaN     NaN     -0.867485   \n",
       "3        0.0           0.0     NaN     NaN     NaN     -0.672717   \n",
       "4        0.0           0.0     NaN     NaN     NaN      0.800258   \n",
       "\n",
       "   weekly_return  volatility_10  volatility_20  price_sma_10_ratio  \\\n",
       "0            NaN            NaN            NaN                 NaN   \n",
       "1            NaN            NaN            NaN                 NaN   \n",
       "2            NaN            NaN            NaN                 NaN   \n",
       "3            NaN            NaN            NaN                 NaN   \n",
       "4            NaN            NaN            NaN                 NaN   \n",
       "\n",
       "   price_sma_20_ratio  next_day_close  target  \n",
       "0                 NaN      302.799988       0  \n",
       "1                 NaN      290.799988       0  \n",
       "2                 NaN      281.950012       0  \n",
       "3                 NaN      292.980011       1  \n",
       "4                 NaN      284.649994       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TSLA Stock Analysis - Stages 03-06\n",
    "# Python Fundamentals, Data Acquisition, Storage, and Preprocessing\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import yfinance as yf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pathlib\n",
    "import datetime as dt\n",
    "from typing import Union, Dict, Any, List\n",
    "\n",
    "# ==================== STAGE 03: PYTHON FUNDAMENTALS ====================\n",
    "print(\"=== STAGE 03: PYTHON FUNDAMENTALS ===\")\n",
    "\n",
    "# Utility Functions (reusable across stages)\n",
    "def ts() -> str:\n",
    "    \"\"\"Generate timestamp string for consistent filenames.\"\"\"\n",
    "    return dt.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "\n",
    "def validate_data(df: pd.DataFrame, required_columns: list) -> Dict[str, Any]:\n",
    "    \"\"\"Validate DataFrame structure and data quality.\"\"\"\n",
    "    validation = {\n",
    "        'missing_columns': [col for col in required_columns if col not in df.columns],\n",
    "        'shape': df.shape,\n",
    "        'na_total': int(df.isna().sum().sum()),\n",
    "        'na_by_column': df.isna().sum().to_dict(),\n",
    "        'dtypes': df.dtypes.to_dict()\n",
    "    }\n",
    "    return validation\n",
    "\n",
    "def detect_format(path: Union[str, pathlib.Path]) -> str:\n",
    "    \"\"\"Detect file format from extension.\"\"\"\n",
    "    path_str = str(path).lower()\n",
    "    if path_str.endswith('.csv'):\n",
    "        return 'csv'\n",
    "    if any(path_str.endswith(ext) for ext in ['.parquet', '.pq', '.parq']):\n",
    "        return 'parquet'\n",
    "    raise ValueError(f'Unsupported format: {path_str}')\n",
    "\n",
    "def read_df(path: Union[str, pathlib.Path]) -> pd.DataFrame:\n",
    "    \"\"\"Read DataFrame from file with automatic format detection.\"\"\"\n",
    "    path_obj = pathlib.Path(path)\n",
    "    fmt = detect_format(path_obj)\n",
    "    \n",
    "    if fmt == 'csv':\n",
    "        try:\n",
    "            sample = pd.read_csv(path_obj, nrows=5)\n",
    "            date_cols = [col for col in sample.columns if 'date' in col.lower()]\n",
    "            if date_cols:\n",
    "                return pd.read_csv(path_obj, parse_dates=date_cols)\n",
    "            return pd.read_csv(path_obj)\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f'Failed to read CSV: {e}')\n",
    "    \n",
    "    elif fmt == 'parquet':\n",
    "        try:\n",
    "            # Specify engine explicitly here too\n",
    "            return pd.read_parquet(path_obj, engine='pyarrow')\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f'Failed to read Parquet: {e}. Install: pip install pyarrow')\n",
    "\n",
    "def write_df(df: pd.DataFrame, path: Union[str, pathlib.Path]) -> pathlib.Path:\n",
    "    path_obj = pathlib.Path(path)\n",
    "    path_obj.parent.mkdir(parents=True, exist_ok=True)\n",
    "    fmt = detect_format(path_obj)\n",
    "    \n",
    "    if fmt == 'csv':\n",
    "        df.to_csv(path_obj, index=False)\n",
    "    elif fmt == 'parquet':\n",
    "        try:\n",
    "            # EXPLICITLY specify engine and compression\n",
    "            df.to_parquet(\n",
    "                path_obj, \n",
    "                engine='pyarrow',  # ← Explicit engine\n",
    "                compression='snappy'  # ← Optional: add compression\n",
    "            )\n",
    "        except Exception as e:\n",
    "            # More helpful error message\n",
    "            raise RuntimeError(f'Failed to write Parquet: {e}. Install: pip install pyarrow')\n",
    "    \n",
    "    return path_obj\n",
    "\n",
    "def calculate_technical_indicators(df: pd.DataFrame, price_col: str = 'close') -> pd.DataFrame:\n",
    "    \"\"\"Calculate common technical indicators for stock data.\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Simple Moving Averages\n",
    "    df['sma_10'] = df[price_col].rolling(window=10).mean()\n",
    "    df['sma_20'] = df[price_col].rolling(window=20).mean()\n",
    "    df['sma_50'] = df[price_col].rolling(window=50).mean()\n",
    "    \n",
    "    # Price Returns\n",
    "    df['daily_return'] = df[price_col].pct_change()\n",
    "    df['weekly_return'] = df[price_col].pct_change(5)\n",
    "    \n",
    "    # Volatility\n",
    "    df['volatility_10'] = df['daily_return'].rolling(window=10).std()\n",
    "    df['volatility_20'] = df['daily_return'].rolling(window=20).std()\n",
    "    \n",
    "    # Price vs SMA ratios\n",
    "    df['price_sma_10_ratio'] = df[price_col] / df['sma_10']\n",
    "    df['price_sma_20_ratio'] = df[price_col] / df['sma_20']\n",
    "    \n",
    "    return df\n",
    "\n",
    "def ensure_data_directories():\n",
    "    \"\"\"Ensure all data directories exist.\"\"\"\n",
    "    directories = ['data/raw', 'data/processed']\n",
    "    for dir_path in directories:\n",
    "        pathlib.Path(dir_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def get_latest_file(directory: Union[str, pathlib.Path], pattern: str = \"*\") -> pathlib.Path:\n",
    "    \"\"\"Get the most recent file in a directory.\"\"\"\n",
    "    dir_path = pathlib.Path(directory)\n",
    "    files = list(dir_path.glob(pattern))\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No files found in {directory} matching {pattern}\")\n",
    "    return max(files, key=lambda x: x.stat().st_mtime)\n",
    "\n",
    "print(\"Utility functions defined and ready for use\\n\")\n",
    "\n",
    "# ==================== STAGE 04: DATA ACQUISITION ====================\n",
    "print(\"=== STAGE 04: DATA ACQUISITION ===\")\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "SYMBOL = os.getenv('YFINANCE_SYMBOL', 'TSLA')\n",
    "ALPHAVANTAGE_API_KEY = os.getenv('ALPHAVANTAGE_API_KEY')\n",
    "\n",
    "def fetch_from_yfinance(symbol, period='6mo', interval='1d'):\n",
    "    \"\"\"Fetch data from Yahoo Finance\"\"\"\n",
    "    try:\n",
    "        ticker = yf.Ticker(symbol)\n",
    "        df = ticker.history(period=period, interval=interval)\n",
    "        df = df.reset_index()\n",
    "        df.columns = [col.lower() for col in df.columns]\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Yahoo Finance error: {e}\")\n",
    "        return None\n",
    "\n",
    "def fetch_from_alphavantage(symbol, api_key):\n",
    "    \"\"\"Fetch data from Alpha Vantage API\"\"\"\n",
    "    if not api_key:\n",
    "        return None\n",
    "    \n",
    "    url = 'https://www.alphavantage.co/query'\n",
    "    params = {\n",
    "        'function': 'TIME_SERIES_DAILY_ADJUSTED',\n",
    "        'symbol': symbol,\n",
    "        'outputsize': 'compact',\n",
    "        'apikey': api_key\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, params=params, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        time_series = data.get('Time Series (Daily)', {})\n",
    "        df = pd.DataFrame.from_dict(time_series, orient='index')\n",
    "        df = df.reset_index().rename(columns={'index': 'date'})\n",
    "        \n",
    "        column_mapping = {\n",
    "            '1. open': 'open', '2. high': 'high', '3. low': 'low',\n",
    "            '4. close': 'close', '5. adjusted close': 'adj_close',\n",
    "            '6. volume': 'volume'\n",
    "        }\n",
    "        df = df.rename(columns=column_mapping)\n",
    "        \n",
    "        numeric_cols = ['open', 'high', 'low', 'close', 'adj_close', 'volume']\n",
    "        for col in numeric_cols:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "            \n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Alpha Vantage API error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Acquire data\n",
    "df = fetch_from_yfinance(SYMBOL)\n",
    "\n",
    "if df is None or df.empty:\n",
    "    df = fetch_from_alphavantage(SYMBOL, ALPHAVANTAGE_API_KEY)\n",
    "\n",
    "if df is not None and not df.empty:\n",
    "    validation = validate_data(df, ['date', 'open', 'high', 'low', 'close', 'volume'])\n",
    "    print(f\"✓ Data acquired: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "    print(f\"   Missing values: {validation['na_total']}\")\n",
    "else:\n",
    "    print(\"Creating sample data for demonstration...\")\n",
    "    dates = pd.date_range('2023-01-01', periods=100, freq='D')\n",
    "    df = pd.DataFrame({\n",
    "        'date': dates,\n",
    "        'open': 150 + np.random.randn(100).cumsum(),\n",
    "        'high': 155 + np.random.randn(100).cumsum(),\n",
    "        'low': 145 + np.random.randn(100).cumsum(),\n",
    "        'close': 150 + np.random.randn(100).cumsum(),\n",
    "        'volume': np.random.randint(1000000, 5000000, 100)\n",
    "    })\n",
    "    print(\"Sample data created\")\n",
    "\n",
    "print(\"\\nFirst few rows:\")\n",
    "display(df.head())\n",
    "\n",
    "# ==================== STAGE 05: DATA STORAGE ====================\n",
    "print(\"\\n=== STAGE 05: DATA STORAGE ===\")\n",
    "\n",
    "# Ensure directories exist\n",
    "ensure_data_directories()\n",
    "RAW_DIR = os.getenv('DATA_DIR_RAW', 'C:/Users/박서아/bootcamp_andrew_song/project/data/raw')\n",
    "PROCESSED_DIR = os.getenv('DATA_DIR_PROCESSED', 'C:/Users/박서아/bootcamp_andrew_song/project/data/processed')\n",
    "\n",
    "# Save raw data\n",
    "raw_filename = f\"tsla_raw_{ts()}.csv\"\n",
    "raw_path = f\"{RAW_DIR}/{raw_filename}\"\n",
    "write_df(df, raw_path)\n",
    "\n",
    "print(f\"✓ Raw data saved: {raw_path}\")\n",
    "\n",
    "processed_filename = f\"tsla_{ts()}.parquet\"\n",
    "processed_path = f\"{PROCESSED_DIR}/{processed_filename}\"\n",
    "write_df(df_clean, processed_path)\n",
    "print(f\"✓ Raw data saved: {processed_path}\")\n",
    "\n",
    "# ==================== STAGE 06: DATA PREPROCESSING ====================\n",
    "print(\"\\n=== STAGE 06: DATA PREPROCESSING ===\")\n",
    "\n",
    "class DataCleaner:\n",
    "    def __init__(self):\n",
    "        self.required_columns = ['date', 'open', 'high', 'low', 'close', 'volume']\n",
    "    \n",
    "    def drop_missing_columns(self, df: pd.DataFrame, threshold: float = 0.5) -> pd.DataFrame:\n",
    "        missing_ratio = df.isnull().mean()\n",
    "        columns_to_drop = missing_ratio[missing_ratio > threshold].index.tolist()\n",
    "        return df.drop(columns=columns_to_drop)\n",
    "    \n",
    "    def fill_missing_values(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        df_clean = df.copy()\n",
    "        numeric_cols = df_clean.select_dtypes(include=[np.number]).columns\n",
    "        \n",
    "        for col in numeric_cols:\n",
    "            if df_clean[col].isnull().any():\n",
    "                df_clean[col] = df_clean[col].fillna(df_clean[col].median())\n",
    "        \n",
    "        if 'date' in df_clean.columns:\n",
    "            df_clean = df_clean.sort_values('date').ffill()\n",
    "        \n",
    "        return df_clean\n",
    "    \n",
    "    def add_technical_indicators(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        return calculate_technical_indicators(df)\n",
    "    \n",
    "    def create_target_variable(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        df_target = df.copy()\n",
    "        df_target['next_day_close'] = df_target['close'].shift(-1)\n",
    "        df_target['target'] = (df_target['next_day_close'] > df_target['close']).astype(int)\n",
    "        return df_target.dropna(subset=['target'])\n",
    "    \n",
    "    def normalize_data(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        numeric_cols = [col for col in numeric_cols if col not in ['target', 'next_day_close']]\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        df_normalized = df.copy()\n",
    "        df_normalized[numeric_cols] = scaler.fit_transform(df_normalized[numeric_cols])\n",
    "        \n",
    "        return df_normalized, scaler\n",
    "    \n",
    "    def clean_data(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
    "        results = {}\n",
    "        initial_validation = validate_data(df, self.required_columns)\n",
    "        results['initial_validation'] = initial_validation\n",
    "        \n",
    "        df_clean = self.drop_missing_columns(df)\n",
    "        df_clean = self.fill_missing_values(df_clean)\n",
    "        df_clean = self.add_technical_indicators(df_clean)\n",
    "        df_clean = self.create_target_variable(df_clean)\n",
    "        df_clean, scaler = self.normalize_data(df_clean)\n",
    "        \n",
    "        results['final_validation'] = validate_data(df_clean, [])\n",
    "        results['scaler'] = scaler\n",
    "        \n",
    "        return df_clean, results\n",
    "\n",
    "# Preprocess the data\n",
    "cleaner = DataCleaner()\n",
    "df_clean, results = cleaner.clean_data(df)\n",
    "\n",
    "# Save processed data as CSV\n",
    "processed_filename = f\"tsla_processed.csv\"\n",
    "processed_path = f\"{PROCESSED_DIR}/{processed_filename}\"\n",
    "write_df(df_clean, processed_path)  \n",
    "\n",
    "print(f\"✓ Processed data saved: {processed_path}\")\n",
    "\n",
    "# Display results\n",
    "print(f\"\\nPreprocessing results:\")\n",
    "print(f\"Rows: {results['initial_validation']['shape'][0]} → {results['final_validation']['shape'][0]}\")\n",
    "print(f\"Columns: {results['initial_validation']['shape'][1]} → {results['final_validation']['shape'][1]}\")\n",
    "print(f\"Missing values: {results['initial_validation']['na_total']} → {results['final_validation']['na_total']}\")\n",
    "\n",
    "print(\"\\nProcessed data sample:\")\n",
    "display(df_clean.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fe-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
